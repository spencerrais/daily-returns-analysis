---
title: "Daily Asset Returns Analysis: Exploring the Data"
output: html_notebook
---
The first thing to be done is to import the data and ensure it comes in currectly.

```{r}
returns = read.table("Returns250d.txt",header = TRUE)
returns$blank <- NULL #erase the first column, which is unnecessary
```

The data is ok, lots of missing values due to staggered start times for various companies introductions to trading.

Below I attempted to add dates to the values, so that interesting days could be marked in future analysis, but was not able to figure out the proper way to go about this.

```{r}
#looking at adding the dates as an extra column, find a way to skip the weekends
#values = seq(from = as.Date("1988-01-04"), to = as.Date("2007-12-24"), by = 'day')
#merge(values,returns, all = T)
require(timeDate)

# A ’timeDate’ Sequence
tS <- timeSequence(as.Date("1988/1/4"), as.Date("2007/12/24"))

# Subset weekdays
tW <- tS[isWeekday(tS)]; tW
length(tW)
#the above unfortunately does not work...which are the days this data is counted for? I counted for all weeks starting from the beginning and have 5211 values as compared to 5039
```

Here the library missMDA is used. It does manage to return values, but unable to estimate any values for the number of parameters which should be retained. Here I have just input an arbitrary value, and have done testing with lower values as well which have also lead to suspicious holes in the time series plot.
```{r}
library(missMDA)
library(FactoMineR)
nbdim <- estim_ncpPCA(returns,scale = TRUE) # estimate the number of dimensions to impute, this only gives out a zero
res.comp <- imputePCA(returns, ncp = 150, scale = TRUE)
res.PCA <- PCA(res.comp[["completeObs"]])

```

Verify that the process looks somewhat stationary. It should be since the data is already given as normalized.

I also check the plots for the values which have been given by missMDA. I notice that there is an interesting flat point which seems out of place.
```{r}
library(zoo)
z<-read.zoo(returns)
plot(z, screen = 1)
plot(res.comp[["completeObs"]],type = "l")


```
This helps visualize the uncertainty in using the predicted values. Still computed using the 'random' value for the number of dimensions used above. Takes a very long time to run, and not particularly useful until I know which data I should be working with, or whether or not I will try putting in estimated values.

```{r}
#mi <- MIPCA(returns, scale = TRUE, ncp = 150)
#plot(mi)
```
One way which the dependencies of a Gaussian, multivariate time series can be estimated is through using spectral analysis. The theory behind using this states that there is marginal independence between two time series(i and j) if the i and j component of the spectral density matrix is equal to 0. This theory also states that there is conditional independence given all other time series if the i and j components of the inverse of the spectral density matrix is also equal to 0. Below I attempt a rough analysis according to this spectral analysis method and attempt to find the marginal and conditional independences. This fails as the matrix is non-square and I can't take a proper inverse.


```{r}
#returns_spectrum <- spectrum(returns)
pcareturns_spectrum <- spectrum(res.comp[["completeObs"]])

```
continuation of the above, test for marginal independences

```{r}
sum(pcareturns_spectrum$spec[,-1] == 0)
#sum(solve(pcareturns_spectrum$spec[,-1] == 0)) #obviouly does not work since the matrix is not square

```

Attempt the power spectral density matrix. find something which works for multivariate time series.
Not sure if this is the right way to continue onwards, but it seems to be the best way to find the dependencies.




